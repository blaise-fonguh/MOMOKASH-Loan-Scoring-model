{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8826b9e8-9536-435b-9530-0f6d2c92d2d2",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053b6bdf-14d6-4142-b32b-79c8fde8f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce001af6-04c6-4e1b-83a7-44bb991fafac",
   "metadata": {},
   "source": [
    "## 2. Load & Filter Data (Sept 2022 – Sept 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646928dc-aa4b-4769-85c5-18a999de4705",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data\\\\processed\\\\integrated_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mprocessed\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mintegrated_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloanDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloanDate\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\n\u001b[0;32m      6\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloanDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2022-09-01\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      7\u001b[0m     (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloanDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2025-09-30\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m ]\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mD:\\apps\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\apps\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\apps\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\apps\\anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\apps\\anaconda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data\\\\processed\\\\integrated_data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\processed\\integrated_data.csv\")\n",
    "\n",
    "\n",
    "df['loanDate'] = pd.to_datetime(df['loanDate'], errors=\"coerce\")\n",
    "df = df[\n",
    "    (df['loanDate'] >= \"2022-09-01\") &\n",
    "    (df['loanDate'] <= \"2025-09-30\")\n",
    "].copy()\n",
    "\n",
    "print(\"Filtered dataset:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579ffba-12f1-48c3-a893-34a531d17142",
   "metadata": {},
   "source": [
    "## 3. Client-Level Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce46b1b6-c752-43ca-a089-72ea90fbb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = (\n",
    "    df.groupby('clientId').agg({\n",
    "        'loanAmount': 'max',\n",
    "        'isBlacklisted': 'first',\n",
    "        'isBlocked': 'first',\n",
    "        'isEligible': 'first',\n",
    "        'isActive': 'first',\n",
    "        'isOwing': 'first',\n",
    "        'dailyLoanCount': 'mean',\n",
    "        'debt': 'mean',\n",
    "        'clientMaxAmount': 'max',\n",
    "        'penaltyDebt': 'mean',\n",
    "        'totalRefunded': 'mean',\n",
    "        'amountPaid': 'sum',\n",
    "        'totalDueAmount': 'sum',\n",
    "        'refund_amount_mean': 'mean',\n",
    "        'refund_amount_std': 'mean'\n",
    "    }).rename(columns={'loanAmount': 'prev_max_loan'}).reset_index()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d1acc2-e9ab-4a98-ac34-31d056c40145",
   "metadata": {},
   "source": [
    "## 4. Extra Behavioural Features (Best Set)/feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3a1fd-f47d-4646-bb77-8c04cd81d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "client['has_late_payments'] = (client['penaltyDebt'] > 0).astype(int)\n",
    "\n",
    "# Loan tenure\n",
    "dates = df.groupby('clientId')['loanDate']\n",
    "client['loan_tenure_days'] = (dates.max() - dates.min()).dt.days.fillna(0)\n",
    "\n",
    "client['num_loans'] = df.groupby('clientId')['loanAmount'].count().values\n",
    "client['mean_refund_frequency'] = df.groupby('clientId')['refund_amount_count'].mean().values\n",
    "client['debt_to_max'] = client['debt'] / (client['clientMaxAmount'] + 1)\n",
    "\n",
    "client['repayment_rate'] = (\n",
    "    client['amountPaid'] / client['totalDueAmount']\n",
    ").replace([np.inf, -np.inf], 0).fillna(0).clip(0, 1)\n",
    "\n",
    "client = client.query(\"prev_max_loan >= 500 and prev_max_loan <= 10000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941f641b-6767-41d6-818f-13d54284f043",
   "metadata": {},
   "source": [
    "## 5. Final Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036c3e0-65a1-4cdb-8881-960964761787",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'prev_max_loan',\n",
    "    'clientMaxAmount',\n",
    "    'repayment_rate',\n",
    "    'num_loans',\n",
    "    'loan_tenure_days',\n",
    "    'debt_to_max',\n",
    "    'penaltyDebt',\n",
    "    'totalRefunded',\n",
    "    'mean_refund_frequency',\n",
    "    'has_late_payments'\n",
    "]\n",
    "\n",
    "X = client[features].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77bc547-b053-4cb2-a239-be4fc324c887",
   "metadata": {},
   "source": [
    "## 6. Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b92db-6995-4f4b-afe3-da5bd4362da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655a1112-2f73-44ab-b324-3ae1ea5b1b4e",
   "metadata": {},
   "source": [
    "## 7. Auto-Select Best k (3–6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7154657-39f2-4fcf-8434-b7152693c390",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for k in range(3, 7):\n",
    "    km = KMeans(n_clusters=k, n_init=20, max_iter=300, random_state=42)\n",
    "    labels = km.fit_predict(X_scaled)\n",
    "\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    db = davies_bouldin_score(X_scaled, labels)\n",
    "    ch = calinski_harabasz_score(X_scaled, labels)\n",
    "\n",
    "    scores.append((k, sil, db, ch))\n",
    "    print(f\"k={k} | Sil={sil:.3f} | DB={db:.3f} | CH={ch:.1f}\")\n",
    "\n",
    "# choose best k by silhouette score\n",
    "best_k = max(scores, key=lambda x: x[1])[0]\n",
    "print(\"\\nSelected best k =\", best_k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1713c740-0e7e-4e1d-a2c6-8bcd069663f9",
   "metadata": {},
   "source": [
    "## 8. Fit Final KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9fb66f-93a1-4393-a5eb-0a4195719a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=best_k, n_init=20, max_iter=300, random_state=42)\n",
    "client['segment'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# === FINAL CLUSTER QUALITY METRICS ===\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "labels = client['segment'].values\n",
    "\n",
    "sil = silhouette_score(X_scaled, labels)\n",
    "db = davies_bouldin_score(X_scaled, labels)\n",
    "ch = calinski_harabasz_score(X_scaled, labels)\n",
    "\n",
    "print(\"\\n=== FINAL CLUSTER QUALITY METRICS (k = {}) ===\".format(kmeans.n_clusters))\n",
    "print(f\"Silhouette Score:       {sil:.3f}\")\n",
    "print(f\"Davies-Bouldin Index:   {db:.3f}\")\n",
    "print(f\"Calinski-Harabasz Index:{ch:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9257c45-e936-4071-a4f4-7237238a3b42",
   "metadata": {},
   "source": [
    "## 9. Map Clusters → Recommended Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f63a7a-8edf-45f6-9a82-41413e06d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_means = client.groupby('segment')['prev_max_loan'].mean().sort_values()\n",
    "tiers = np.linspace(500, 10000, best_k).round(-2)\n",
    "\n",
    "mapping = dict(zip(segment_means.index, tiers))\n",
    "client['recommended_max_loan'] = client['segment'].map(mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887cc32b-769e-4102-bf49-2e6b7017afca",
   "metadata": {},
   "source": [
    "## 10.  Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815e98c-56f1-47b9-966e-64dcf5735231",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump({\n",
    "    'scaler': scaler,\n",
    "    'kmeans': kmeans,\n",
    "    'features': features,\n",
    "    'mapping': mapping\n",
    "}, \"loan_model.pkl\")\n",
    "\n",
    "print(\"Model saved ✔️\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713a63f9-cc7f-42f8-9ef8-e424c5490539",
   "metadata": {},
   "source": [
    "## 11. Scoring Function (Backend-Ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7245ecd7-8bfb-4387-86aa-b6ecb9ffaf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_client(client_row):\n",
    "    model = joblib.load(\"loan_model.pkl\")\n",
    "    scaler = model['scaler']\n",
    "    kmeans = model['kmeans']\n",
    "    mapping = model['mapping']\n",
    "    feats = model['features']\n",
    "\n",
    "    row = pd.DataFrame([client_row[feats]])\n",
    "    scaled = scaler.transform(row)\n",
    "    seg = kmeans.predict(scaled)[0]\n",
    "    amount = mapping[seg]\n",
    "\n",
    "    return {\n",
    "        \"segment\": int(seg),\n",
    "        \"recommended_amount\": int(amount),\n",
    "        \"amount_fcfa\": f\"{int(amount):,} FCFA\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff60f05-84e4-4415-a073-e99c74170be7",
   "metadata": {},
   "source": [
    "## 12.  PCA Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9fc1c-8bce-4276-9856-978b1540ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt\n",
    "\n",
    "# PCA transformation\n",
    "pca = PCA(n_components=2).fit_transform(X_scaled)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(\n",
    "    pca[:,0], pca[:,1],\n",
    "    c=client['segment'],\n",
    "    cmap='tab10',\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title(\"Client Behaviour Clusters\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save first, then show\n",
    "plt.savefig('outputs/client_behaviour_clusters.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9298a-dd69-48b2-be01-dd05e329c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 12. RANDOM SAMPLE CHECK\n",
    "# ===========================\n",
    "\n",
    "def inspect_random_clients(\n",
    "    client,\n",
    "    features,\n",
    "    scaler,\n",
    "    kmeans,\n",
    "    mapping,\n",
    "    n_samples=5,\n",
    "    seed=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Pick n_samples random clients and show:\n",
    "      - clientId\n",
    "      - cluster (segment)\n",
    "      - prev_max_loan\n",
    "      - recommended_max_loan\n",
    "      - repayment_rate\n",
    "      - has_late_payments\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== RANDOM SAMPLE CLIENTS (n={n_samples}) ===\")\n",
    "\n",
    "    # Random sample (seed=None → new random clients every run)\n",
    "    samples = client.sample(n=n_samples, random_state=seed)\n",
    "\n",
    "    for idx, row in samples.iterrows():\n",
    "\n",
    "        # Extract features for prediction\n",
    "        feats = pd.DataFrame([row[features].fillna(0)], columns=features)\n",
    "        scaled = scaler.transform(feats)\n",
    "        seg = kmeans.predict(scaled)[0]\n",
    "        rec = mapping[seg]\n",
    "\n",
    "        print(\n",
    "            f\"ClientId: {row['clientId']} | \"\n",
    "            f\"Cluster: {seg} | \"\n",
    "            f\"PrevMaxLoan: {row['prev_max_loan']:.0f} FCFA → \"\n",
    "            f\"Recommended Max Loan: {rec:.0f} FCFA | \"\n",
    "            f\"RepaymentRate: {row['repayment_rate']:.2%} | \"\n",
    "            f\"LatePayments: {int(row.get('has_late_payments', 0))}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c52eb1-0c05-4715-bc34-9c2266baf287",
   "metadata": {},
   "source": [
    "## 13. Client Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff3799-4dbd-488b-8559-8c67574451ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_random_clients(\n",
    "    client=client,\n",
    "    features=features,\n",
    "    scaler=scaler,\n",
    "    kmeans=kmeans,\n",
    "    mapping=mapping,\n",
    "    n_samples=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2a317-f004-463b-869c-f0095b156fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_random_clients(client, features, scaler, kmeans, mapping, n_samples=3, seed=None)\n",
    "inspect_random_clients(client, features, scaler, kmeans, mapping, n_samples=3, seed=5)\n",
    "inspect_random_clients(client, features, scaler, kmeans, mapping, n_samples=3, seed=99)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa50f29-52fc-4d91-be6c-602bbd98401f",
   "metadata": {},
   "source": [
    "## 14. Scoring Logic for New Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2f6fb-1d92-4204-a25c-c7bb95f87fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_new_client_with_progression(client_data):\n",
    "    \"\"\"\n",
    "    Enhanced scoring:\n",
    "    - New clients (no history)\n",
    "    - Early clients (1–2 loans)\n",
    "    - Mature clients (3+ loans)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Completely new client → no loan history\n",
    "    if client_data['num_loans'] == 0:\n",
    "        return {\n",
    "            'segment': -1,\n",
    "            'recommended_amount': 500,   # entry amount\n",
    "            'risk_level': 'NEW CLIENT (UNKNOWN RISK)',\n",
    "            'color': 'GRAY',\n",
    "            'comment': 'New client with no history. Assigned starter loan.'\n",
    "        }\n",
    "    \n",
    "    # 2. Early-phase client (1–2 loans)\n",
    "    if client_data['num_loans'] <= 2:\n",
    "        # Simple rule: if repayment good so far → small upgrade\n",
    "        if client_data.get('repayment_rate', 0) > 0.8:\n",
    "            amt = 1500\n",
    "        else:\n",
    "            amt = 800\n",
    "        \n",
    "        return {\n",
    "            'segment': -2,\n",
    "            'recommended_amount': amt,\n",
    "            'risk_level': 'EARLY CLIENT (LIMITED HISTORY)',\n",
    "            'color': 'LIGHT BLUE',\n",
    "            'comment': 'Early customer. Temporary rule-based limit.'\n",
    "        }\n",
    "    \n",
    "    # 3. Mature client (3+ loans) → use clustering\n",
    "    import joblib\n",
    "    model = joblib.load(\"loan_model.pkl\")\n",
    "    scaler = model['scaler']\n",
    "    kmeans = model['kmeans']\n",
    "    mapping = model['mapping']\n",
    "    features = model['features']\n",
    "\n",
    "    row = pd.DataFrame([client_data[features]])\n",
    "    scaled = scaler.transform(row)\n",
    "    seg = kmeans.predict(scaled)[0]\n",
    "    amount = mapping[seg]\n",
    "\n",
    "    return {\n",
    "        'segment': int(seg),\n",
    "        'recommended_amount': int(amount),\n",
    "        'risk_level': 'BEHAVIORAL MODEL APPLIED',\n",
    "        'color': 'GREEN',\n",
    "        'comment': 'Behavioural cluster-based credit limit assigned.'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dc72b9-f1a0-49fb-a4b6-8f4a4c54bfd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
